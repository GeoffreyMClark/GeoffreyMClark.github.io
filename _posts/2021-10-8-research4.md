---
layout: post
title: "Learning Legged Locomotion"
author: "Geoffrey Clark"
categories: research
# tags: [research]
image: robot_training.png
gif: robot_testing_hq.gif
---

![](assets/img/robot_training_hq.gif){:style="float:left; margin-left:10px; margin-top:10px; padding-right:25px; width: 45%;"} 
![](assets/img/robot_testing_hq.gif){:style="float:right; margin-left:10px; margin-top:10px; padding-right:25px; width: 45%;"}

Since I, unfortunately, do not have access to a high-quality legged robot I chose to explore reinforcement learning on the <a href="https://ieeexplore.ieee.org/abstract/document/8793865?casa_token=zHMedQLqVzYAAAAA:wlqT53qaz0uIONO0bZwkz1CWvRXDt1-KsCqvWqSI3ZAihnIPL1pMG9HXptoPgsILlNRoF4oRRQ" target="_blank">MIT Mini Cheetah</a> in simulation. I used reinforcement learning to train a locomotion model in the  simulation environment. Specifically, the robot learned to walk and run up to 10m/s, as well as to crouch to walk under low objects. Since I do not have a physical robot for testing I ported both the robot and learned neural network into <a href="https://unity.com/" target="_blank">Unity</a> for high-fidelity simulation. Porting the robot and controller into a new simulation environment poses the same challenges as porting them to a real-world robot. Minor differences in the environments mean that the controller must be extreemly robust in order to effectively control the robot. To accomplish this sim-to-sim transfer I trained my control policy while varrying critical simulation parameters such as friction, mass, and control timing, in addition to adding varrying noise to each sensor. The training process took approximately 2 hours and simulated over 15days of robot time. Untimately, my training resulted in a robust and effective control policy what I can drive around the simulated world with a controller. I am currently working on adding jumping, flipping over, and aditional sensing capabilities to the robot.

## Further Information
For further information, or to follow along with my progress please consult my [github repository](https://github.com/GeoffreyMClark).

